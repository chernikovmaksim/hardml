{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2919a81-1bc3-43a6-9b60-a4c29782b276",
   "metadata": {},
   "source": [
    "## Lambda rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca792e5a-f7ed-429b-9ef5-41b1b51d8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from catboost.datasets import msrank_10k\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    \"\"\"\n",
    "    Сlass creates a gradient boosting model based on Lambda calculation, \n",
    "    trains and validates it.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_estimators: int = 100, \n",
    "        lr: float = 0.5, \n",
    "        ndcg_top_k: int = 10,\n",
    "        subsample: float = 0.6, \n",
    "        colsample_bytree: float = 0.9,\n",
    "        max_depth: int = 5, \n",
    "        min_samples_leaf: int = 8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_estimators (int): Number of epochs.\n",
    "            lr (float): Learning rate.\n",
    "            ndcg_top_k (int): NDCG metric score for top k.\n",
    "            subsample (float): The proportion of objects from the sample on which each tree is trained.\n",
    "            colsample_bytree (float): The proportion of features from the sample on which each tree is trained.\n",
    "            max_depth (int): Tree building depth.\n",
    "            min_samples_leaf (int): The minimum number in the terminal (final) leaves of the tree.\n",
    "        \"\"\"\n",
    "        self._prepare_data()\n",
    "        self.ndcg_top_k = ndcg_top_k\n",
    "        self.ndcg_scheme = \"exp2\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        \n",
    "        self.n_objects_train, self.n_features_ = self.X_train.size()\n",
    "        self.n_objects_test = self.X_test.size()[0]\n",
    "        self.n_subsample = int(self.n_objects_train * self.subsample)\n",
    "        self.n_subfeatures = int(self.n_features_ * self.colsample_bytree)\n",
    "        \n",
    "        self.trees = [\n",
    "            DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                random_state=i,\n",
    "            ) \n",
    "            for i in range(self.n_estimators)\n",
    "        ]\n",
    "        self.tree_features = []\n",
    "        self.train_ndsgs = []\n",
    "        self.test_ndcgs = []\n",
    "        self.best_ndcg = -1\n",
    "        self.best_idx = -1\n",
    "\n",
    "    def _get_data(self) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Method loads data for training and test.\n",
    "        \"\"\"\n",
    "        train_df, test_df = msrank_10k()\n",
    "\n",
    "        X_train = train_df.drop([0, 1], axis=1).values\n",
    "        y_train = train_df[[0]].values\n",
    "        query_ids_train = train_df[1].values.astype(int)\n",
    "\n",
    "        X_test = test_df.drop([0, 1], axis=1).values\n",
    "        y_test = test_df[[0]].values\n",
    "        query_ids_test = test_df[1].values.astype(int)\n",
    "\n",
    "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
    "\n",
    "    def _prepare_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Method prepares data for training and test.\n",
    "        \"\"\"\n",
    "        (X_train, y_train, self.query_ids_train,\n",
    "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
    "        X_train = self._scale_features_in_query_groups(X_train, self.query_ids_train)\n",
    "        X_test = self._scale_features_in_query_groups(X_test, self.query_ids_test)\n",
    "        self.X_train, self.ys_train, self.X_test, self.ys_test = map(torch.FloatTensor,\n",
    "                                                                    [X_train, y_train, X_test, y_test])\n",
    "        self.query_ids_train_u = np.unique(self.query_ids_train)\n",
    "        self.query_ids_test_u = np.unique(self.query_ids_test)\n",
    "\n",
    "\n",
    "    def _scale_features_in_query_groups(\n",
    "            self, \n",
    "            inp_feat_array: np.ndarray,\n",
    "            inp_query_ids: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Method normalizes the input data.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for q_id in np.unique(inp_query_ids):\n",
    "            result.append(StandardScaler().fit_transform(inp_feat_array[inp_query_ids == q_id]))\n",
    "        return np.vstack(result)  \n",
    "\n",
    "    def _train_one_tree(\n",
    "        self, \n",
    "        cur_tree_idx: int, \n",
    "        train_preds: torch.FloatTensor\n",
    "    ) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Method for training one tree.\n",
    "        \"\"\"\n",
    "        lambdas = torch.zeros(self.n_objects_train, 1)\n",
    "        \n",
    "        for query_id in self.query_ids_train_u:\n",
    "            idx_q = self.query_ids_train == query_id\n",
    "            lambdas[idx_q] = self._compute_lambdas(self.ys_train[idx_q], train_preds[idx_q])\n",
    "        \n",
    "        idx_sample = np.random.choice(self.n_objects_train, self.n_subsample, replace=False)\n",
    "        feature_sample = np.random.choice(self.n_features_, self.n_subfeatures, replace=False)\n",
    "        \n",
    "        regressor = self.trees[cur_tree_idx]\n",
    "        regressor.fit(self.X_train[idx_sample, :][:, feature_sample], -lambdas[idx_sample])\n",
    "        \n",
    "        return regressor, feature_sample\n",
    "\n",
    "    def _calc_data_ndcg(\n",
    "            self, \n",
    "            queries_list: np.ndarray,\n",
    "            true_labels: torch.FloatTensor, \n",
    "            preds: torch.FloatTensor\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Method for calculating data NDCG.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            ndcgs = []\n",
    "            for query_id in np.unique(queries_list):\n",
    "                idx_q = queries_list == query_id\n",
    "                ndcg = self._ndcg_k(true_labels[idx_q], preds[idx_q], self.ndcg_top_k)\n",
    "                if np.isnan(ndcg):\n",
    "                    ndcg = 0\n",
    "                ndcgs.append(ndcg)        \n",
    "        return np.mean(ndcgs)\n",
    "    \n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Method for training k trees and find the best NDCG score and tree id.\n",
    "        \"\"\"\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        train_preds = torch.zeros(self.n_objects_train, 1)\n",
    "        test_preds = torch.zeros(self.n_objects_test, 1)\n",
    "        \n",
    "        for idx_tree in tqdm(range(self.n_estimators)):\n",
    "            tree, feature_sample = self._train_one_tree(idx_tree, train_preds)\n",
    "            self.trees.append(tree)\n",
    "            self.tree_features.append(feature_sample)\n",
    "            \n",
    "            X_train_cur = self.X_train[:, feature_sample]\n",
    "            train_preds += self.lr * torch.FloatTensor(tree.predict(X_train_cur)).reshape(-1, 1)\n",
    "            train_ndcg = self._calc_data_ndcg(self.query_ids_train, self.ys_train, train_preds)\n",
    "            self.test_ndcgs.append(train_ndcg)\n",
    "            \n",
    "            X_test_cur = self.X_test[:, feature_sample]\n",
    "            test_preds += self.lr * torch.FloatTensor(tree.predict(X_test_cur)).reshape(-1, 1)\n",
    "            test_ndcg = self._calc_data_ndcg(self.query_ids_test, self.ys_test, test_preds)\n",
    "            self.test_ndcgs.append(test_ndcg)\n",
    "            \n",
    "            if test_ndcg > self.best_ndcg:\n",
    "                self.best_ndcg = test_ndcg\n",
    "                # print(self.best_ndcg)\n",
    "                self.best_idx = idx_tree\n",
    "        \n",
    "        self.trees = self.trees[:self.best_idx+1]\n",
    "        self.tree_features = self.tree_features[:self.best_idx+1]\n",
    "        self.train_ndsgs = self.test_ndcgs[:self.best_idx+1]\n",
    "        self.test_ndsgs = self.test_ndcgs[:self.best_idx+1]\n",
    "\n",
    "    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Method for making prediction.\n",
    "        \"\"\"\n",
    "        preds = torch.zeros(data.shape[0], 1)\n",
    "        for tree, features in zip(self.trees, self.tree_features):\n",
    "            preds += self.lr * tree.predict(data[:, features]).reshape(-1, 1)\n",
    "        return preds\n",
    "\n",
    "    def _compute_lambdas(self, y_true: torch.FloatTensor, y_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Method for computing lambdas.\n",
    "        \"\"\"\n",
    "        # рассчитаем нормировку, IdealDCG\n",
    "        ideal_dcg = self._dcg_k(y_true, y_true, self.ndcg_scheme)\n",
    "        \n",
    "        if ideal_dcg:\n",
    "            N = 1 / ideal_dcg\n",
    "        else:\n",
    "            N = 0.0\n",
    "\n",
    "        # рассчитаем порядок документов согласно оценкам релевантности\n",
    "        _, rank_order = torch.sort(y_true, descending=True, axis=0)\n",
    "        rank_order += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # получаем все попарные разницы скоров в батче\n",
    "            pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
    "            # поставим разметку для пар, 1 если первый документ релевантнее\n",
    "            # -1 если второй документ релевантнее\n",
    "            Sij = self._compute_labels_in_batch(y_true)\n",
    "            # посчитаем изменение gain из-за перестановок\n",
    "            gain_diff = self._compute_gain_diff(y_true, self.ndcg_scheme)\n",
    "            # посчитаем изменение знаменателей-дискаунтеров\n",
    "            decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n",
    "            # посчитаем непосредственное изменение nDCG\n",
    "            delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n",
    "            # посчитаем лямбды\n",
    "            lambda_update =  (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n",
    "            lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n",
    "\n",
    "        return lambda_update\n",
    "        \n",
    "    def _compute_labels_in_batch(self, y_true:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Method compute_labels_in_batch.\n",
    "        \"\"\"\n",
    "        # разница релевантностей каждого с каждым объектом\n",
    "        rel_diff = y_true - y_true.t()\n",
    "\n",
    "        # 1 в этой матрице - объект более релевантен\n",
    "        pos_pairs = (rel_diff > 0).type(torch.float32)\n",
    "\n",
    "        # 1 тут - объект менее релевантен\n",
    "        neg_pairs = (rel_diff < 0).type(torch.float32)\n",
    "        Sij = pos_pairs - neg_pairs\n",
    "        return Sij\n",
    "    \n",
    "    def _compute_gain_diff(self, y_true: torch.Tensor, gain_scheme: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Method for calculating gain diff.\n",
    "        \"\"\"\n",
    "        if gain_scheme == \"exp2\":\n",
    "            gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n",
    "        elif gain_scheme == \"diff\":\n",
    "            gain_diff = y_true - y_true.t()\n",
    "        else:\n",
    "            raise ValueError(f\"{gain_scheme} gain method not supported\")\n",
    "        return gain_diff\n",
    "\n",
    "    def _compute_gain(self, y_value: float, gain_scheme: str) -> float:\n",
    "        \"\"\"\n",
    "        Method for calculating DCG and NDCG, which calculates Gain.\n",
    "        \"\"\"\n",
    "        if gain_scheme == \"const\":\n",
    "            return y_value\n",
    "        elif gain_scheme == \"exp2\":\n",
    "            return 2**y_value - 1\n",
    "        else:\n",
    "            raise ValueError(f\"{gain_scheme} gain method not supported\")\n",
    "                          \n",
    "    def _dcg_k(\n",
    "        self, \n",
    "        ys_true: torch.Tensor, \n",
    "        ys_pred: torch.Tensor, \n",
    "        gain_scheme: str = \"exp2\", \n",
    "        k: int = None\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Method to calculate the DCG at k. \n",
    "        https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
    "        \n",
    "        Args:\n",
    "            ys_true (torch.Tensor): Tensor of actual relevancy values.\n",
    "            ys_pred (torch.Tensor): Tensor of predicted relevancy values.\n",
    "            gain_scheme (str): Gain scheme.\n",
    "            k (int) : Choose highest k scores in the ranking.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: DCG at k metric.\n",
    "        \"\"\"\n",
    "        order = torch.argsort(ys_pred, descending=True, dim=0)\n",
    "        true_sorted_by_preds = torch.gather(ys_true, dim=0, index=order)\n",
    "\n",
    "        gain_function = lambda x: self._compute_gain(x, gain_scheme)\n",
    "        gains = gain_function(true_sorted_by_preds)\n",
    "\n",
    "        discounts = torch.tensor(1) /  torch.log2(torch.arange(true_sorted_by_preds.shape[0], dtype=torch.double) + 2.0).unsqueeze(-1)\n",
    "        if k is not None:\n",
    "            discounts[k:] = 0\n",
    "        discounted_gains = gains * discounts\n",
    "\n",
    "        sum_dcg = torch.sum(discounted_gains, dim=0)\n",
    "        return float(sum_dcg)\n",
    "                          \n",
    "    def _ndcg_k(\n",
    "        self, \n",
    "        ys_true: torch.Tensor, \n",
    "        ys_pred: torch.Tensor, \n",
    "        ndcg_top_k: int,\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Method to calculate the NDCG at k. \n",
    "        https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
    "        \n",
    "        Args:\n",
    "            ys_true (torch.Tensor): Tensor of actual relevancy values.\n",
    "            ys_pred (torch.Tensor): Tensor of predicted relevancy values.\n",
    "            gain_scheme (str): Gain scheme.\n",
    "            k (int) : Choose highest k scores in the ranking.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: NDCG at k metric.\n",
    "        \"\"\"\n",
    "        ideal_dcgs = self._dcg_k(ys_true, ys_true, self.ndcg_scheme, ndcg_top_k)\n",
    "        predicted_dcgs = self._dcg_k(ys_true, ys_pred, self.ndcg_scheme, ndcg_top_k)\n",
    "        if ideal_dcgs == 0:\n",
    "            return 0\n",
    "        return predicted_dcgs/ ideal_dcgs\n",
    "    \n",
    "    def save_model(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Method saves the model.\n",
    "        \n",
    "        Args:\n",
    "            path (str): Path to model.\n",
    "        \"\"\"\n",
    "        state = {\n",
    "            \"trees\" : self.trees,\n",
    "            \"tree_features\" : self.tree_features,\n",
    "            \"best_ndcg\": self.best_ndcg,\n",
    "            \"best_idx\": self.best_idx,\n",
    "            \"lr\": self.lr\n",
    "        }\n",
    "        with open(path, \"wb\") as output_file:\n",
    "            pickle.dump(state, output_file)\n",
    "\n",
    "    def load_model(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Method loads the model.\n",
    "        \n",
    "        Args:\n",
    "            path (str): Path to model.\n",
    "        \"\"\"\n",
    "        with open(path, \"rb\") as input_file:\n",
    "            state = pickle.load(input_file)\n",
    "        self.trees = state[\"trees\"]\n",
    "        self.tree_features = state[\"tree_features\"]\n",
    "        self.best_ndcg = state[\"best_ndcg\"]\n",
    "        self.best_idx = state[\"best_idx\"]\n",
    "        self.lr = state[\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4bff7e-89ea-42c4-891c-4127e3168ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with best params\n",
    "model = Solution( \n",
    "        lr=0.514863, \n",
    "        subsample=0.419661, \n",
    "        colsample_bytree=0.937201,\n",
    "        max_depth=30, \n",
    "        min_samples_leaf=14\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ee99e5-14b9-4437-863b-2bf3558500df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87dc27872a74b29b0d454354293b3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549b631b-c42a-4876-b4c3-9908c65ee256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43711583807783116, 69)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_ndcg, model.best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926db5c8-6e4a-4c7a-b7ab-f77254e4619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"./model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cb1424-f816-44bd-b121-8dd69180daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model(\"./model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9092e6c1-2b48-4dac-abfa-7dcb4c3ffccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(model.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9da9aba-ea98-4a8c-b805-df9c2d325c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43711583807783116"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._calc_data_ndcg(model.query_ids_test, model.ys_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d36671-ae89-41aa-9913-acc9a66cbc14",
   "metadata": {},
   "source": [
    "## Find best params with Hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599cfafd-60b5-482f-a5ca-9ae4cfe2d107",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/donkeys/exploring-hyperopt-parameter-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a88f0aba-440a-4159-a8ff-bf474c2cda54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'var1'}>]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "low = 0\n",
    "high = 1\n",
    "values = []\n",
    "space = hp.uniform('something', low, high)\n",
    "for x in range(10000):\n",
    "    values.append(hyperopt.pyll.stochastic.sample(space))\n",
    "df = pd.DataFrame(values, columns=[\"var1\"])\n",
    "df.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40701de-484d-4500-94ff-cf842345093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import hyperopt\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "search_space = {\n",
    "    # 'criterion': hp.choice('criterion', [\"squared_error\", \"friedman_mse\", \"absolute_error\"]),\n",
    "    'lr': hp.uniform(\"lr\", 0, 1),\n",
    "    # 'lr':  hp.choice(\"lr\", np.arange(0.01, 1, 0.01)),\n",
    "    'subsample': hp.uniform(\"subsample\", 0, 1),\n",
    "    # 'subsample': hp.choice(\"subsample\", np.arange(0.3, 1, 0.01)),\n",
    "    'colsample_bytree': hp.uniform(\"colsample_bytree\", 0, 1),\n",
    "    # 'colsample_bytree': hp.choice(\"colsample_bytree\", np.arange(0.2, 1, 0.01)),\n",
    "    'max_depth' :  hp.choice('max_depth', range(1,31)),\n",
    "    'min_samples_leaf' : hp.choice('min_samples_leaf', range(1,21)),\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    model = Solution(**params)\n",
    "    model.fit()\n",
    "    # возвращаем результаты, которые записываются в Trials()\n",
    "    return   {'loss': -model.best_ndcg, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b64216f-efe8-4e18-a425-512170286bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/40 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54689709cf4d4adc861bc6797cc49738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                               | 1/40 [00:26<17:28, 26.87s/trial, best loss: -0.368882469460574]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b7f53f76e14a039c47b6fe6a4111d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|██▍                                              | 2/40 [00:46<14:19, 22.61s/trial, best loss: -0.368882469460574]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abe818d6d37415484256f946fcfe9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|███▋                                             | 3/40 [02:46<41:27, 67.22s/trial, best loss: -0.368882469460574]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c559f49bc207423e939092827d1cd539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|████▊                                           | 4/40 [04:24<47:26, 79.08s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4687b99c944df28d67c3b60b6afb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|██████                                          | 5/40 [04:54<35:51, 61.48s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c42ff29bdbe43568c2e50e328cda1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|███████▏                                        | 6/40 [06:56<46:27, 82.00s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b0c5e5349e43b8b01ef591786c2a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|████████▍                                       | 7/40 [07:51<40:14, 73.16s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161b2cce0d6b4b2381507c03aee39c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|█████████▌                                      | 8/40 [08:28<33:00, 61.88s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5188cf50fa24e98bd8e1394f60df12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██████████▊                                     | 9/40 [09:40<33:36, 65.06s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803c8abac65444bc9bfbea28f76446cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|███████████▊                                   | 10/40 [10:00<25:29, 50.98s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76d9f4708da438ca167db9e4c359b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|████████████▉                                  | 11/40 [10:23<20:34, 42.57s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d297aece754575b5e99643e22a314a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|██████████████                                 | 12/40 [11:06<19:56, 42.73s/trial, best loss: -0.4120340848410301]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a16f6dba094b3a81d2ed9330eb308f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|██████████████▉                               | 13/40 [12:08<21:46, 48.37s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aa146f46334e1b83b0ef5789f258e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|████████████████                              | 14/40 [13:11<22:57, 52.97s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e258dcd7f9f44bfd9add95ee178cd7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████▎                            | 15/40 [13:31<17:51, 42.88s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be7313c7ca84991b131857f80ccc1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████▍                           | 16/40 [14:14<17:10, 42.95s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c12d7bdad74a4d864ad7057edb03ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████▌                          | 17/40 [14:32<13:36, 35.51s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40567a420d541e680f2dfde1308b495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████▋                         | 18/40 [15:15<13:47, 37.60s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a308232b32de491fbfcef7bafe755e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████▊                        | 19/40 [16:40<18:12, 52.02s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef6111803964806a61122e885937289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████                       | 20/40 [16:59<13:58, 41.92s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3102effe2e34e1cbb499bc60eb2facc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████▏                     | 21/40 [17:41<13:17, 41.97s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccddb0d5ce9b4ee3ae958393e20f3f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████▎                    | 22/40 [18:49<14:58, 49.93s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846f034f3db246a1aa017bc97fc24e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████▍                   | 23/40 [19:09<11:33, 40.81s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8583572da148413981201c50539a1763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████▌                  | 24/40 [19:54<11:16, 42.28s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5f5d9e2a1145fda54ffb0673b76d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████▊                 | 25/40 [20:40<10:50, 43.38s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802acdb8a03c4a9e8ae6a3bfd1a3731f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████▉                | 26/40 [20:58<08:19, 35.71s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76aaa696e68b4c5da0247f0e605b15e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████               | 27/40 [21:50<08:47, 40.60s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8c7fc582de414e9b239b48ac31e623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████▏             | 28/40 [22:35<08:21, 41.79s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82c18076dbb47b680657e4559e8b014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████▎            | 29/40 [23:29<08:19, 45.40s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21929f7611e40e9b6b598e9f8d1cd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████▌           | 30/40 [24:31<08:24, 50.48s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbab2a2edbb4c9a8505a96079cc97cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████▋          | 31/40 [25:27<07:49, 52.13s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d37a2d556294859850a7d7d5867a4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████▊         | 32/40 [25:48<05:41, 42.71s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a3dfdbbe294f7e8690cd4531f7b649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████▉        | 33/40 [26:08<04:11, 35.89s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20590c44ab7e4162a2663840a18cfb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████       | 34/40 [27:10<04:22, 43.79s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4d55f268bd40f09af6e4c0875202f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████▎     | 35/40 [28:25<04:26, 53.23s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee40b5afe6a49fe90d93170112fe01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████▍    | 36/40 [29:02<03:13, 48.36s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409fc4318fe84216bcf88c50494f16c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████▌   | 37/40 [29:33<02:09, 43.01s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306a455b7f574fd4a3056ceb256e7205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████▋  | 38/40 [29:57<01:14, 37.49s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea7d923c3924d6a89010ec7765fd2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████▊ | 39/40 [31:34<00:55, 55.16s/trial, best loss: -0.43711583807783116]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e9246ef7e645ae8fd7dedcdc162877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 40/40 [32:09<00:00, 48.24s/trial, best loss: -0.43711583807783116]\n"
     ]
    }
   ],
   "source": [
    "# запускаем hyperopt\n",
    "trials = Trials()\n",
    "best = fmin( \n",
    "          # функция для оптимизации  \n",
    "            fn=objective,\n",
    "          # пространство поиска гиперпараметров  \n",
    "            space=search_space,\n",
    "          # алгоритм поиска\n",
    "            algo=tpe.suggest,\n",
    "          # число итераций \n",
    "          # (можно ещё указать и время поиска) \n",
    "            max_evals=40,\n",
    "          # куда сохранять историю поиска\n",
    "            trials=trials,\n",
    "          # random state\n",
    "            rstate=np.random.default_rng(1),\n",
    "          # progressbar\n",
    "            show_progressbar=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e57384-af81-49cc-8e88-5e4cf1adb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def df_results(hp_results: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Display Hyperopt results in DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        hp_results (dict): Hyperopt results.\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\" \n",
    "\n",
    "    results = pd.DataFrame([{**x, **x['params']} for x in  hp_results])\n",
    "    results.drop(labels=['status', 'params'], axis=1, inplace=True)\n",
    "    results.sort_values(by=['loss'], ascending=True, inplace=True)\n",
    "    return results\n",
    "\n",
    "results = df_results(trials.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcfa4cfd-b8e9-4b2a-9a72-46bb126b6f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>lr</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.437116</td>\n",
       "      <td>0.937201</td>\n",
       "      <td>0.514863</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>0.419661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.430935</td>\n",
       "      <td>0.913301</td>\n",
       "      <td>0.385164</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.519452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.425236</td>\n",
       "      <td>0.822866</td>\n",
       "      <td>0.413698</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.465233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.422326</td>\n",
       "      <td>0.804991</td>\n",
       "      <td>0.446986</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0.433352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.415174</td>\n",
       "      <td>0.877650</td>\n",
       "      <td>0.721568</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.807154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.414831</td>\n",
       "      <td>0.848599</td>\n",
       "      <td>0.688619</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.790778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.413442</td>\n",
       "      <td>0.997894</td>\n",
       "      <td>0.157043</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0.377997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.412034</td>\n",
       "      <td>0.867019</td>\n",
       "      <td>0.258968</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0.823266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.412010</td>\n",
       "      <td>0.277271</td>\n",
       "      <td>0.622270</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.544466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.411975</td>\n",
       "      <td>0.698171</td>\n",
       "      <td>0.847418</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0.980202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.411323</td>\n",
       "      <td>0.764541</td>\n",
       "      <td>0.367346</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0.621084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.410388</td>\n",
       "      <td>0.739518</td>\n",
       "      <td>0.359644</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>0.609384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.409465</td>\n",
       "      <td>0.649610</td>\n",
       "      <td>0.595013</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.447700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.407960</td>\n",
       "      <td>0.618386</td>\n",
       "      <td>0.122328</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>0.367736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.407375</td>\n",
       "      <td>0.609464</td>\n",
       "      <td>0.125089</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>0.371542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.404381</td>\n",
       "      <td>0.899134</td>\n",
       "      <td>0.543565</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.746653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.404147</td>\n",
       "      <td>0.827425</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0.595487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.398225</td>\n",
       "      <td>0.537094</td>\n",
       "      <td>0.799702</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.532661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.394463</td>\n",
       "      <td>0.079116</td>\n",
       "      <td>0.325310</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.153378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.394306</td>\n",
       "      <td>0.952660</td>\n",
       "      <td>0.167232</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>0.257475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.394282</td>\n",
       "      <td>0.968656</td>\n",
       "      <td>0.359658</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.255876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.387184</td>\n",
       "      <td>0.780707</td>\n",
       "      <td>0.407640</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>0.088673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.379473</td>\n",
       "      <td>0.150196</td>\n",
       "      <td>0.302896</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>0.149462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.379417</td>\n",
       "      <td>0.731383</td>\n",
       "      <td>0.645049</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.378565</td>\n",
       "      <td>0.929008</td>\n",
       "      <td>0.059018</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.421637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.368882</td>\n",
       "      <td>0.226492</td>\n",
       "      <td>0.555094</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.510136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.367385</td>\n",
       "      <td>0.423473</td>\n",
       "      <td>0.249621</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.365496</td>\n",
       "      <td>0.331023</td>\n",
       "      <td>0.993263</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.634231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.364243</td>\n",
       "      <td>0.994725</td>\n",
       "      <td>0.010473</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.363707</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>0.929242</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.578535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.360895</td>\n",
       "      <td>0.450641</td>\n",
       "      <td>0.652360</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.359512</td>\n",
       "      <td>0.692578</td>\n",
       "      <td>0.783245</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>0.174604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.357900</td>\n",
       "      <td>0.922955</td>\n",
       "      <td>0.462593</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.209536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.356367</td>\n",
       "      <td>0.539972</td>\n",
       "      <td>0.511917</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0.021333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.354486</td>\n",
       "      <td>0.863795</td>\n",
       "      <td>0.888536</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.337158</td>\n",
       "      <td>0.084072</td>\n",
       "      <td>0.220705</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.706337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.331520</td>\n",
       "      <td>0.986423</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.009157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.319311</td>\n",
       "      <td>0.337826</td>\n",
       "      <td>0.560043</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.511796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.261704</td>\n",
       "      <td>0.016934</td>\n",
       "      <td>0.757617</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.858246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.243359</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.705199</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  colsample_bytree        lr  max_depth  min_samples_leaf  \\\n",
       "12 -0.437116          0.937201  0.514863         30                14   \n",
       "29 -0.430935          0.913301  0.385164         16                20   \n",
       "28 -0.425236          0.822866  0.413698         16                20   \n",
       "26 -0.422326          0.804991  0.446986         16                11   \n",
       "33 -0.415174          0.877650  0.721568          8                20   \n",
       "38 -0.414831          0.848599  0.688619         24                 8   \n",
       "21 -0.413442          0.997894  0.157043         25                 7   \n",
       "3  -0.412034          0.867019  0.258968         25                14   \n",
       "36 -0.412010          0.277271  0.622270         11                14   \n",
       "34 -0.411975          0.698171  0.847418         12                 9   \n",
       "13 -0.411323          0.764541  0.367346         17                16   \n",
       "6  -0.410388          0.739518  0.359644         13                18   \n",
       "27 -0.409465          0.649610  0.595013         14                11   \n",
       "23 -0.407960          0.618386  0.122328         30                13   \n",
       "20 -0.407375          0.609464  0.125089         30                14   \n",
       "30 -0.404381          0.899134  0.543565          7                10   \n",
       "8  -0.404147          0.827425  0.453744         19                 8   \n",
       "31 -0.398225          0.537094  0.799702          1                 6   \n",
       "19 -0.394463          0.079116  0.325310         15                17   \n",
       "24 -0.394306          0.952660  0.167232         25                12   \n",
       "35 -0.394282          0.968656  0.359658         10                20   \n",
       "37 -0.387184          0.780707  0.407640         29                18   \n",
       "14 -0.379473          0.150196  0.302896         27                16   \n",
       "18 -0.379417          0.731383  0.645049         26                 1   \n",
       "39 -0.378565          0.929008  0.059018          5                 2   \n",
       "0  -0.368882          0.226492  0.555094         11                 9   \n",
       "32 -0.367385          0.423473  0.249621          2                 5   \n",
       "17 -0.365496          0.331023  0.993263         21                 4   \n",
       "5  -0.364243          0.994725  0.010473         27                 1   \n",
       "16 -0.363707          0.036133  0.929242          4                15   \n",
       "7  -0.360895          0.450641  0.652360         20                 2   \n",
       "4  -0.359512          0.692578  0.783245         18                14   \n",
       "15 -0.357900          0.922955  0.462593         22                 3   \n",
       "25 -0.356367          0.539972  0.511917          3                19   \n",
       "2  -0.354486          0.863795  0.888536         27                 1   \n",
       "10 -0.337158          0.084072  0.220705         15                 3   \n",
       "22 -0.331520          0.986423  0.033180          9                 7   \n",
       "11 -0.319311          0.337826  0.560043         28                 1   \n",
       "1  -0.261704          0.016934  0.757617         21                 2   \n",
       "9  -0.243359          0.015258  0.705199         17                 1   \n",
       "\n",
       "    subsample  \n",
       "12   0.419661  \n",
       "29   0.519452  \n",
       "28   0.465233  \n",
       "26   0.433352  \n",
       "33   0.807154  \n",
       "38   0.790778  \n",
       "21   0.377997  \n",
       "3    0.823266  \n",
       "36   0.544466  \n",
       "34   0.980202  \n",
       "13   0.621084  \n",
       "6    0.609384  \n",
       "27   0.447700  \n",
       "23   0.367736  \n",
       "20   0.371542  \n",
       "30   0.746653  \n",
       "8    0.595487  \n",
       "31   0.532661  \n",
       "19   0.153378  \n",
       "24   0.257475  \n",
       "35   0.255876  \n",
       "37   0.088673  \n",
       "14   0.149462  \n",
       "18   0.679100  \n",
       "39   0.421637  \n",
       "0    0.510136  \n",
       "32   0.300299  \n",
       "17   0.634231  \n",
       "5    0.602516  \n",
       "16   0.578535  \n",
       "7    0.333334  \n",
       "4    0.174604  \n",
       "15   0.209536  \n",
       "25   0.021333  \n",
       "2    0.860700  \n",
       "10   0.706337  \n",
       "22   0.009157  \n",
       "11   0.511796  \n",
       "1    0.858246  \n",
       "9    0.927237  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
